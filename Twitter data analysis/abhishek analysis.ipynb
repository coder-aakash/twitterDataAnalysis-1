{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''this contains your secret key and token data from twitter account and OAuth Verification.\n",
    "   Also u can use api method to access twiiter Api (api = tweepy.API(auth))'''\n",
    "import configAbhishek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api=configAbhishek.api  #very important line: to access your own account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL SEARCH METHOD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tweet(tweet):\n",
    "    print('@{} - {}'.format(tweet.user.screen_name, tweet.user.name))\n",
    "    print(tweet.text)\n",
    "    print('')\n",
    "\n",
    "\n",
    "\n",
    "result = api.search(q = 'MIvsRPS')\n",
    "#for tweet in result:\n",
    "   #print_tweet(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get the Trending Topics\n",
    "   =========================================================\n",
    " 1. The REST API provides an indirect method to get the trends.\n",
    " 2. We need a WOEID of a place to get the most trending topics in that place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a list of all available places and their WOEID¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "places_woeid = {}\n",
    "places = api.trends_available()\n",
    "#print(places[1])\n",
    "for x in places:\n",
    "    places_woeid.update({x['name'] : x['woeid']})\n",
    "#print(places_woeid['Ranchi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends = api.trends_place(places_woeid['Ranchi'])\n",
    "#print(trends[0]['trends'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly this is a List of a single Dictionary\n",
    " 1. We can access the singular elements of the dictionary as trends[0]['trends']\n",
    " 2. Now for each trending topic, the three important info are its name valuea and its query value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#KennethJuster - %23KennethJuster\n",
      "#GoogleDoodle - %23GoogleDoodle\n",
      "Meira Kumar - %22Meira+Kumar%22\n",
      "#OwnTheWorld - %23OwnTheWorld\n",
      "Boris Becker - %22Boris+Becker%22\n",
      "#Anilkumble - %23Anilkumble\n",
      "#ZinnovConfluence - %23ZinnovConfluence\n",
      "#NationalSelfieDay - %23NationalSelfieDay\n",
      "#ParmanuFirstLook - %23ParmanuFirstLook\n",
      "#WinterIsHere - %23WinterIsHere\n",
      "#ENGvSA - %23ENGvSA\n",
      "#ThursdayThoughts - %23ThursdayThoughts\n",
      "#WorldMusicDay - %23WorldMusicDay\n",
      "#RamNathKovind - %23RamNathKovind\n",
      "#VasanaMillaVanamagan - %23VasanaMillaVanamagan\n",
      "#HBDThalapathy - %23HBDThalapathy\n",
      "#TubelightKaDost - %23TubelightKaDost\n",
      "#BJP_KisanMuktasan - %23BJP_KisanMuktasan\n",
      "#FairozKhanNSUI - %23FairozKhanNSUI\n",
      "#Radha - %23Radha\n",
      "Rajiv Gauba - %22Rajiv+Gauba%22\n",
      "#WoApniEidiLeneAarahaHai - %23WoApniEidiLeneAarahaHai\n",
      "#CorruptNaddaCagedCBI - %23CorruptNaddaCagedCBI\n",
      "#ShahInNadiad - %23ShahInNadiad\n",
      "#WednesdayWisdom - %23WednesdayWisdom\n",
      "#Pulwama - %23Pulwama\n",
      "Mosul - Mosul\n",
      "#OnePlus5Launch - %23OnePlus5Launch\n",
      "#RepublicStingsISI - %23RepublicStingsISI\n",
      "#PSLVC38 - %23PSLVC38\n",
      "#CSKarnan - %23CSKarnan\n",
      "Tatas - Tatas\n",
      "#CongBolBachchan - %23CongBolBachchan\n"
     ]
    }
   ],
   "source": [
    "all_trends = {}\n",
    "for x in trends[0]['trends']:\n",
    "    all_trends.update({x['name'] : x['query']})\n",
    "\n",
    "for k, v in all_trends.items():\n",
    "    print('{} - {}'.format(k , v))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the tweets on any specific trending topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'#IPLfinal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2640303e354a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_trends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'#IPLfinal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '#IPLfinal'"
     ]
    }
   ],
   "source": [
    "tweets = api.search(q = str(all_trends['#IPLfinal']))\n",
    "#for tweet in tweets:\n",
    "   # print_tweet(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API search method\n",
    "### Help Methods\n",
    "   **API.search(q[, lang][, locale][, rpp][, page][, since_id][, geocode][, show_user])**\n",
    "   **Returns** tweets that match a specifieduery. \n",
    "   **Parameters:**\n",
    "   >  * q – the search query string\n",
    "      * lang – Restricts tweets to the given language, given by an ISO 639-1 code.\n",
    "      * locale – Specify the language of the query you are sending. This is intended for language-specific clients the default           should work in the majority of cases.\n",
    "      * rpp – The number of tweets to return per page, up to a max of 100.\n",
    "      * page – The page number (starting at 1) to return, up to a max of roughly 1500 results (based on rpp * page.\n",
    "      * since_id – Returns only statuses with an ID greater than (that is, more recent than) the specified ID.\n",
    "      * geocode – Returns tweets by users located within a given radius of the given latitude/longitude. The location is                 preferentially taking from the Geotagging API, but will fall back to their Twitter profile. The parameter value is               specified by “latitide,longitude,radius”, where radius units must be specified as either “mi” (miles) or “km”                   (kilometers). Note that you cannot use the near operator via the API to geocode arbitrary locations; however you can use         this geocode parameter to search near geocodes directly.\n",
    "      * show_user – When true, prepends '(user)' to the beginning of the tweet. This is useful for readers that do not display            Atom’s author field. The default is false.\n",
    "      \n",
    "  ** Return type:**\n",
    "  list of SearchResult objects\n",
    " \n",
    "\n",
    "\n",
    "   > eg api.search(q=\"Bangalore\",lang='en', geocode=\"12.897489,77.607422,1km\",show_user=True)\n",
    "   So one can use the parameter corresponding to the geo location to get the tweets of that\n",
    "   location, of the trending topics\n",
    "   we need to to set query of that of the trending topic and location of that place\n",
    "   Another important topic \n",
    "   [Cursor Tutorial](http://docs.tweepy.org/en/v3.5.0/cursor_tutorial.html)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### suggested future project ideas:\n",
    " 1. Most polpular trends : by relative number of tweets and retweets , frequency of tweets and (optional)probablity of retweet\n",
    " 2. Most popular person, car brand , politician , programming language , movie etc\n",
    " 3. The tweet-retweet graph: using networkx\n",
    " 4. Future project(much later): Most important keywords assoiciated with a trend or news and sentimental analysis of this trend     as piechart   \n",
    "    and coloured geographical map. Finally Sumarise the trend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### some improvements to try\n",
    "1. Proper Database for tweets storage\n",
    "2. Generalizing a popularity analyser for specific topics, specific people etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
